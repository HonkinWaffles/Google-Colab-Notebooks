{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HonkinWaffles/Google-Colab-Notebooks/blob/main/Honkin_Stable_Diffusion_%2B_ESRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion with ESRGAN Upscaling\n",
        "\n",
        "### Repos:\n",
        "* Stable Diffusion:https://github.com/CompVis/stable-diffusion\n",
        "\n",
        "  * Optimized Fork: https://github.com/basujindal/stable-diffusion\n",
        "\n",
        "* Real-ESRGAN: https://github.com/xinntao/Real-ESRGAN/\n",
        "\n",
        "### Other Information:\n",
        "* Model Data: v1.4\n"
      ],
      "metadata": {
        "id": "pyEMJsFQ7wKK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8oErRw9M65"
      },
      "source": [
        "# Optimized* TXT2IMG \n",
        "Images as large as 578x1024 but at the cost of render times."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stable Diffusion\n"
      ],
      "metadata": {
        "id": "QsX6d0mdtsRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QrbRAtUF_BLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get Nvidia-SMI\n"
      ],
      "metadata": {
        "id": "gFkQoTbJr9bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "simple_nvidia_smi_display = False\n",
        "nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(nvidiasmi_output)\n",
        "nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(nvidiasmi_ecc_note)"
      ],
      "metadata": {
        "id": "ZeltFCT33vdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c529124a-1695-4110-a8fb-3e782a340ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  8 05:51:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                   0* |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "ECC support is already Disabled for GPU 00000000:00:04.0.\n",
            "All done.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "Vt_0AdpceOdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "\n",
        "import os, torch, gc, shutil, wget\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "root_dir='/content/'\n",
        "stable_diffusion= '/content/stable-diffusion'\n",
        "real_esrgan= '/content/Real-ESRGAN'\n",
        "\n",
        "#Start of command always switch to root\n",
        "os.chdir(root_dir)\n",
        "\n",
        "#Login to GDRIVE for file access\n",
        "LOGIN_GDRIVE = True\n",
        "if LOGIN_GDRIVE and not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "## Drive paths for Google Colab\n",
        "# Root = /content/drive/MyDrive/GOOGLE_COLAB/\n",
        "# Setup Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP\n",
        "# img2img Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG\n",
        "# txt2img Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG\n",
        "\n",
        "## Make directory structure in drive to set everything up correctly\n",
        "!mkdir -p /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG/INPUT /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG/OUTPUT /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG\n",
        "!mkdir -p /content/drive/MyDrive/GOOGLE_COLAB/ESRGAN /content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP /content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/OUTPUT \n",
        "\n",
        "## Check if file exists in Drive if not download - \n",
        "\n",
        "path_to_file = '/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/Miniconda3-latest-Linux-x86_64.sh'\n",
        "path = Path(path_to_file)\n",
        "\n",
        "if path.is_file():\n",
        "    shutil.copy2('/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/Miniconda3-latest-Linux-x86_64.sh', '/content/')\n",
        "    print('Copying local version of Conda')\n",
        "else:\n",
        "    wget.download('https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh')\n",
        "    print('Downloading Miniconda from internet - Consider adding a copy to `/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/`')\n",
        "\n",
        "# Install Miniconda\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda init bash\n",
        "!conda install wget diffusers basicsr facexlib gfpgan -y\n",
        "\n",
        "# Clone Basujindal Stable-Diffusion\n",
        "!git clone https://github.com/basujindal/stable-diffusion.git\n",
        "!mkdir -p /content/stable-diffusion/models/ldm/stable-diffusion-v1/\n",
        "\n",
        "## Download Stable Diffusion v1.4 Model\n",
        "path_to_file = '/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/sd-v1-4-full-ema.ckpt'\n",
        "path = Path(path_to_file)\n",
        "if path.is_file():\n",
        "    print('Copying local version of models ')\n",
        "    shutil.copy2('/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/sd-v1-4-full-ema.ckpt', 'stable-diffusion/models/ldm/stable-diffusion-v1/model.ckpt')\n",
        "else:\n",
        "    wget.download('https://www.googleapis.com/storage/v1/b/aai-blog-files/o/sd-v1-4.ckpt?alt=media','models/ldm/stable-diffusion-v1/model.ckpt' )\n",
        "    print('Downloading model from internet - Consider adding the better copy from `Huggingface` to `stable-diffusion/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/`')\n",
        "\n",
        "!conda env update -n base -f /content/stable-diffusion/environment.yaml\n",
        "\n",
        "\n",
        "# Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "os.chdir(real_esrgan)\n",
        "!python -m pip install -r  /content/Real-ESRGAN/requirements.txt\n",
        "!python /content/Real-ESRGAN/setup.py develop\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# Download Real-ESRGAN Pretrained Model\n",
        "path_to_file = '/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/RealESRGAN_x4plus.pth'\n",
        "path = Path(path_to_file)\n",
        "if path.is_file():\n",
        "    shutil.copy2('/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/RealESRGAN_x4plus.pth', '/content/Real-ESRGAN/experiments/pretrained_models/RealESRGAN_x4plus.pth')\n",
        "    print('Copying local version of models')\n",
        "else:\n",
        "    wget.download('https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth', '/content/Real-ESRGAN/experiments/pretrained_models/RealESRGAN_x4plus.pth')\n",
        "    print('Downloading Models from internet - Consider downloading and adding it to `/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/`')\n",
        "\n",
        "#End of command directory check\n",
        "os.chdir(root_dir)"
      ],
      "metadata": {
        "id": "6B2iZClMeQ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TXT2IMG"
      ],
      "metadata": {
        "id": "fOaD1nOueUhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hhTd65bQZObr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zX1Srtlh7iO"
      },
      "outputs": [],
      "source": [
        "root_dir='/content/'\n",
        "stable_diffusion= '/content/stable-diffusion'\n",
        "real_esrgan= '/content/Real-ESRGAN'\n",
        "\n",
        "#Start of command always switch to root\n",
        "os.chdir(root_dir)\n",
        "\n",
        "\n",
        "#@markdown Fill out the prompt and image details then run the code to generate images\n",
        "\n",
        "#@markdown ---\n",
        "PROMPT = \"Evil witch vampire, long hair, ornate, elegant, amazing, intricate, extremely detailed, smooth, beautiful composition, sharp focus, illustration, concept art, digital painting, greg rutkowski, yoshitaka amano, frank frazetta, boris vallejo, sorceress, magic, fantasy, demonic, radiating magical power, extremely detailed, face details\" #@param {type:'string'}\n",
        "STEPS = 125 #@param {type:\"slider\", min:5, max:500, step:5} \n",
        "SEED = 0 #@param {type:'integer'}\n",
        "NUM_ITERS = 1 #@param {type:\"slider\", min:1, max:100, step:1} \n",
        "HEIGHT = 704 #@param {type:\"slider\", min:256, max:1920, step:64}\n",
        "WIDTH = 384 #@param {type:\"slider\", min:256, max:1920, step:64}\n",
        "SCALE = 7.5 #@param {type:\"slider\", min:0, max:25, step:0.1}\n",
        "FILE_PATH = \"/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG/\" #@param {type:'string'}\n",
        "#@markdown ---\n",
        "AUTO_UPSCALE = True #@param {type:\"boolean\"}\n",
        "OUT_SCALE = 2 #@param {type:'integer'}\n",
        "FACE_ENHANCE = False #@param {type:\"boolean\"}\n",
        "#@markdown Precision during inference (16-32) \n",
        "FP = 32 #@param {type:\"slider\", min:16, max:32, step:16}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "# Stable diffusion - Generate txt2img\n",
        "os.chdir(stable_diffusion)\n",
        "if SEED is 0:\n",
        "  print('Generating Image')\n",
        "  !python /content/stable-diffusion/optimizedSD/optimized_txt2img.py \\\n",
        "  --n_samples 1 \\\n",
        "  --n_iter $NUM_ITERS \\\n",
        "  --scale $SCALE \\\n",
        "  --H $HEIGHT \\\n",
        "  --W $WIDTH \\\n",
        "  --ddim_steps $STEPS \\\n",
        "  --outdir $FILE_PATH \\\n",
        "  --prompt \"$PROMPT\"\n",
        "else:\n",
        "  !python /content/stable-diffusion/optimizedSD/optimized_txt2img.py \\\n",
        "  --n_samples 1 \\\n",
        "  --n_iter $NUM_ITERS \\\n",
        "  --scale $SCALE \\\n",
        "  --H $HEIGHT \\\n",
        "  --W $WIDTH \\\n",
        "  --seed $SEED \\\n",
        "  --ddim_steps $STEPS \\\n",
        "  --outdir $FILE_PATH \\\n",
        "  --prompt \"$PROMPT\"\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# Real-ESRGAN - \n",
        "os.chdir(real_esrgan)\n",
        "\n",
        "FILE_PATH = FILE_PATH + (PROMPT.replace(\" \", \"_\"))[0:94]\n",
        "print(FILE_PATH)\n",
        "\n",
        "if AUTO_UPSCALE is True:\n",
        "    if FACE_ENHANCE is True:\n",
        "      print('Upscaling Images')\n",
        "      !python inference_realesrgan.py \\\n",
        "        -n RealESRGAN_x4plus \\\n",
        "        -i $FILE_PATH \\\n",
        "        --fp$FP \\\n",
        "        --outscale $OUT_SCALE \\\n",
        "        --face_enhance \n",
        "      !rm -rf $FILE_PATH/*\n",
        "      !cp /content/Real-ESRGAN/results/* $FILE_PATH/\n",
        "      !rm /content/Real-ESRGAN/results/*\n",
        "    else:\n",
        "      print('Upscaling Images')\n",
        "      !python inference_realesrgan.py \\\n",
        "        -n RealESRGAN_x4plus \\\n",
        "        -i $FILE_PATH \\\n",
        "        --fp$FP \\\n",
        "        --outscale $OUT_SCALE \n",
        "      !rm -rf $FILE_PATH/*\n",
        "      !cp /content/Real-ESRGAN/results/* $FILE_PATH/\n",
        "      !rm /content/Real-ESRGAN/results/*\n",
        "\n",
        "      \n",
        "#End of command directory check\n",
        "os.chdir(root_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline TXT2IMG"
      ],
      "metadata": {
        "id": "-Ak-C1UrKyxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses HuggingFace Pipeline for image generation, much faster.\n",
        "Allows for Bul  "
      ],
      "metadata": {
        "id": "-spFDZW4twTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NVIDIA-SMI"
      ],
      "metadata": {
        "id": "xicaMEhh8F5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "simple_nvidia_smi_display = False\n",
        "nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(nvidiasmi_output)\n",
        "nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(nvidiasmi_ecc_note)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z8G-dPz8I1B",
        "outputId": "01eee9e4-dcce-484e-e4aa-27419545c0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  8 08:10:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "Disabled ECC support for GPU 00000000:00:04.0.\n",
            "All done.\n",
            "Reboot required.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "9GDQ3mwCZyBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive paths for Google Colab\n",
        "# Root = /content/drive/MyDrive/GOOGLE_COLAB/\n",
        "# Setup Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP\n",
        "# img2img Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG\n",
        "# txt2img Files = /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG\n",
        "\n",
        "## Install Requirements \n",
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "!pip install wget\n",
        "\n",
        "## Directory Variables \n",
        "root_dir='/content/'\n",
        "stable_diffusion= '/content/stable-diffusion'\n",
        "real_esrgan= '/content/Real-ESRGAN'\n",
        "\n",
        "## Load Requirements\n",
        "import os, torch, gc, shutil, wget\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "from huggingface_hub import notebook_login\n",
        "from google.colab import output\n",
        "\n",
        "## Login to GDRIVE for file access\n",
        "LOGIN_GDRIVE = True\n",
        "if LOGIN_GDRIVE and not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "## Make directory structure in drive for Stable Diff\n",
        "!mkdir -p /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG/INPUT /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/IMG2IMG/OUTPUT /content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG\n",
        "\n",
        "## Login to Hugging Face API\n",
        "path_to_file = '/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/SETUP/token'\n",
        "path = Path(path_to_file)\n",
        "\n",
        "## Check for file of Hugging Face Token \n",
        "if path.is_file():\n",
        "    text_file = open(path_to_file, \"r\")\n",
        "    token = text_file.read()\n",
        "    text_file.close()\n",
        "    !echo $token | huggingface-cli login\n",
        "else:\n",
        "    print('No token found please login manually')\n",
        "    output.enable_custom_widget_manager()\n",
        "    notebook_login()\n",
        "\n",
        "# Setup Real-ESRGAN for upscaling \n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "os.chdir(real_esrgan)\n",
        "!python -m pip install -r  /content/Real-ESRGAN/requirements.txt\n",
        "!python /content/Real-ESRGAN/setup.py develop\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# Download Real-ESRGAN Pretrained Model\n",
        "path_to_file = '/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/RealESRGAN_x4plus.pth'\n",
        "path = Path(path_to_file)\n",
        "if path.is_file():\n",
        "    shutil.copy2('/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/RealESRGAN_x4plus.pth', '/content/Real-ESRGAN/experiments/pretrained_models/RealESRGAN_x4plus.pth')\n",
        "    print('Copying local version of models')\n",
        "else:\n",
        "    wget.download('https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth', '/content/Real-ESRGAN/experiments/pretrained_models/RealESRGAN_x4plus.pth')\n",
        "    print('Downloading Models from internet - Consider downloading and adding it to `/content/drive/MyDrive/GOOGLE_COLAB/ESRGAN/SETUP/`')\n",
        "\n",
        "#End of command directory check\n",
        "os.chdir(root_dir)\n"
      ],
      "metadata": {
        "id": "0tCejdYJEM6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Pipeline"
      ],
      "metadata": {
        "id": "3bOZ1cXPZ0ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import shutil \n",
        "import subprocess\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from traitlets.config.loader import DeferredConfigString\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "## Defines pipeline clean \n",
        "def clean_env():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "## Cleans the environment before loading the pipe\n",
        "clean_env()\n",
        "\n",
        "## Starts the Stable Diffusion pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)  \n",
        "pipe = pipe.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "949uJI-lKltN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TXT2IMG"
      ],
      "metadata": {
        "id": "kU-dU34JZ5gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import shutil \n",
        "import subprocess\n",
        "import subprocess as sp\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from traitlets.config.loader import DeferredConfigString\n",
        "from google.colab import files\n",
        "\n",
        "# File System Paths \n",
        "root_dir='/content/'\n",
        "stable_diffusion= '/content/stable-diffusion'\n",
        "real_esrgan= '/content/Real-ESRGAN'\n",
        "\n",
        "## Returns to the root directory\n",
        "os.chdir(root_dir)\n",
        "\n",
        "def dummy(images, **kwargs):\n",
        "  return images, False\n",
        "\n",
        "#@markdown Fill out the prompt and image details then run the code to generate images\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Either upload a list of prompts or enter a single prompt \n",
        "UPLOAD_PROMPTS_LIST = False #@param {type:\"boolean\"}\n",
        "PROMPT = \"Test12\" #@param {type:'string'}\n",
        "#@markdown ---\n",
        "#@markdown Stable Diffusion Options\n",
        "STEPS=10 #@param {type:\"slider\", min:5, max:500, step:5} \n",
        "SEED=0 #@param {type:'integer'}\n",
        "NUM_ITERS=1 #@param {type:\"slider\", min:1, max:100, step:1} \n",
        "WIDTH=512 #@param {type:\"slider\", min:256, max:1920, step:64}\n",
        "HEIGHT=512 #@param {type:\"slider\", min:256, max:1920, step:64}\n",
        "GUIDANCE_SCALE= 7 #@param {type:\"slider\", min:1, max:10, step:0.5}\n",
        "#SCALE=15.3 #@param {type:\"slider\", min:0, max:25, step:0.1}\n",
        "OUTDIR=\"Round-1\" #@param {type:'string'}\n",
        "DISABLE_NSFW_FILTER = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown  Real-ESRGAN Options\n",
        "AUTO_UPSCALE = True #@param {type:\"boolean\"}\n",
        "OUT_SCALE = 2 #@param {type:'integer'}\n",
        "FACE_ENHANCE = False #@param {type:\"boolean\"}\n",
        "#@markdown Precision during inference (16-32) \n",
        "FP = 32 #@param {type:\"slider\", min:16, max:32, step:16}\n",
        "#@markdown ---\n",
        "\n",
        "OUTPUT=\"/content/drive/MyDrive/GOOGLE_COLAB/STABLE_DIFF/TXT2IMG/\" + OUTDIR + \"/\"\n",
        "\n",
        "## Disables the NSFW filter if enabled \n",
        "if DISABLE_NSFW_FILTER is True:\n",
        "  pipe.safety_checker = dummy\n",
        "\n",
        "## Setup folders for Uploads + Results \n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "os.mkdir(upload_folder)\n",
        "os.mkdir(result_folder)\n",
        "\n",
        "## Sets the prompts_split variable to user entered or parse the txt file uploaded by the user \n",
        "if UPLOAD_PROMPTS_LIST is True:\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(upload_folder, filename)\n",
        "    shutil.move(filename, dst_path)\n",
        "  prompts_file = open(dst_path)\n",
        "  prompts_imported = prompts_file.read()\n",
        "  prompts_split = prompts_imported.splitlines()\n",
        "else:\n",
        "  prompts_split = [PROMPT]\n",
        "\n",
        "## Loops through each of the prompts by the number of iters set by the user \n",
        "\n",
        "for x in range(NUM_ITERS):\n",
        "  for i in prompts_split:\n",
        "    with autocast(\"cuda\"):\n",
        "      as_string = str(x)\n",
        "      path = i [0:25]\n",
        "      path = OUTPUT + path\n",
        "      isExist = os.path.exists(path)\n",
        "      if not isExist:\n",
        "        os.makedirs(path)\n",
        "      if SEED is 0:\n",
        "        image = pipe(i, num_inference_steps=STEPS, height=HEIGHT, width=WIDTH, guidance_scale=GUIDANCE_SCALE)[\"sample\"][0]\n",
        "      else:\n",
        "        image = pipe(i, num_inference_steps=STEPS, height=HEIGHT, width=WIDTH, guidance_scale=GUIDANCE_SCALE, seed=SEED)[\"sample\"][0]\n",
        "      image.save(path + '/' +\"Image_\" + as_string +'.png', 'PNG')         \n",
        "\n",
        "## Upscales generated images if selected \n",
        "if AUTO_UPSCALE is True:\n",
        "  path = \"\\\"\" + path + \"\\\"\"\n",
        "  clean_env()\n",
        "  os.chdir(real_esrgan)\n",
        "  if FACE_ENHANCE is True:\n",
        "      print('Upscaling Images')\n",
        "      !python inference_realesrgan.py \\\n",
        "        -n RealESRGAN_x4plus \\\n",
        "        -i $path \\\n",
        "        --fp$FP \\\n",
        "        --outscale $OUT_SCALE \\\n",
        "        --face_enhance \n",
        "      !rm -rf $path/*\n",
        "      !cp /content/Real-ESRGAN/results/* $path/\n",
        "      !rm /content/Real-ESRGAN/results/*\n",
        "  else:\n",
        "      print('Upscaling Images')\n",
        "      !python inference_realesrgan.py \\\n",
        "        -n RealESRGAN_x4plus \\\n",
        "        -i $path \\\n",
        "        --fp$FP \\\n",
        "        --outscale $OUT_SCALE \n",
        "      !rm -rf $path/*\n",
        "      !cp /content/Real-ESRGAN/results/* $path/\n",
        "      !rm /content/Real-ESRGAN/results/*\n",
        "\n",
        "## Returns to the root directory\n",
        "os.chdir(root_dir)"
      ],
      "metadata": {
        "id": "av4cNPhYDaUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9be4a55acde2419384ac46333ed39c57",
            "16ddb6307a694dc8bcf82bea468f26b3",
            "67a867fa6c4f40ceae21a3b00a2461d7",
            "0fc60900f4e94f978b3acdf938d1f115",
            "9b71816368ba442e8412dc784fbe2687",
            "4b7b77c6c2ac4b84b62babade901f6f6",
            "47cc2afd71e847d1b25f9e5ed425c9d5",
            "825f8b0e7e8948c5a7c81c0cf5e16e48",
            "ff3b056e71154902b0d92604b3caa583",
            "4d6a02fe044548e8aa19a249651610d0",
            "121e1c7de96841a7889bfeedd3748818"
          ]
        },
        "outputId": "0c6d53a1-4cc3-4e47-e25a-abff72f36991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9be4a55acde2419384ac46333ed39c57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upscaling Images\n",
            "Testing 0 Image_0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gFkQoTbJr9bP",
        "fOaD1nOueUhO",
        "6PH_b9jKeeK6",
        "-Ak-C1UrKyxN",
        "9GDQ3mwCZyBc",
        "3bOZ1cXPZ0ow",
        "kU-dU34JZ5gD"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9be4a55acde2419384ac46333ed39c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16ddb6307a694dc8bcf82bea468f26b3",
              "IPY_MODEL_67a867fa6c4f40ceae21a3b00a2461d7",
              "IPY_MODEL_0fc60900f4e94f978b3acdf938d1f115"
            ],
            "layout": "IPY_MODEL_9b71816368ba442e8412dc784fbe2687"
          }
        },
        "16ddb6307a694dc8bcf82bea468f26b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7b77c6c2ac4b84b62babade901f6f6",
            "placeholder": "​",
            "style": "IPY_MODEL_47cc2afd71e847d1b25f9e5ed425c9d5",
            "value": ""
          }
        },
        "67a867fa6c4f40ceae21a3b00a2461d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_825f8b0e7e8948c5a7c81c0cf5e16e48",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff3b056e71154902b0d92604b3caa583",
            "value": 1
          }
        },
        "0fc60900f4e94f978b3acdf938d1f115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6a02fe044548e8aa19a249651610d0",
            "placeholder": "​",
            "style": "IPY_MODEL_121e1c7de96841a7889bfeedd3748818",
            "value": " 11/? [00:03&lt;00:00,  3.48it/s]"
          }
        },
        "9b71816368ba442e8412dc784fbe2687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7b77c6c2ac4b84b62babade901f6f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47cc2afd71e847d1b25f9e5ed425c9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825f8b0e7e8948c5a7c81c0cf5e16e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ff3b056e71154902b0d92604b3caa583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d6a02fe044548e8aa19a249651610d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121e1c7de96841a7889bfeedd3748818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}